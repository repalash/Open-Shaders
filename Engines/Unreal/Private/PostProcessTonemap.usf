// Copyright Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	PostProcessTonemap.usf: PostProcessing tone mapping  
=============================================================================*/

#define EYE_ADAPTATION_LOOSE_PARAMETERS 1

#include "Common.ush"
#include "PostProcessCommon.ush"
#include "TonemapCommon.ush"
#include "EyeAdaptationCommon.ush"
#include "PixelQuadMessagePassing.ush"
#include "ScreenPass.ush"

/** Values of DIM_OUTPUT_DEVICE (matching C++'s ETonemapperOutputDevice) */
#define TONEMAPPER_OUTPUT_sRGB 0
#define TONEMAPPER_OUTPUT_Rec709 1
#define TONEMAPPER_OUTPUT_ExplicitGammaMapping 2
#define TONEMAPPER_OUTPUT_ACES1000nitST2084 3
#define TONEMAPPER_OUTPUT_ACES2000nitST2084 4
#define TONEMAPPER_OUTPUT_ACES1000nitScRGB 5
#define TONEMAPPER_OUTPUT_ACES2000nitScRGB 6
#define TONEMAPPER_OUTPUT_LinearEXR 7
#define TONEMAPPER_OUTPUT_NoToneCurve 8
#define TONEMAPPER_OUTPUT_WithToneCurve 9

#ifndef DIM_OUTPUT_DEVICE
	#define DIM_OUTPUT_DEVICE (TONEMAPPER_OUTPUT_sRGB)
#endif





// 0 / 1(slower, visualize multiple internals side by side for the same image portion, see DebugTile)
#define DEBUG_TONEMAPPER 0

SCREEN_PASS_TEXTURE_VIEWPORT(Color)
SCREEN_PASS_TEXTURE_VIEWPORT(Bloom)
SCREEN_PASS_TEXTURE_VIEWPORT(Output)
SCREEN_PASS_TEXTURE_VIEWPORT_TRANSFORM(ColorToBloom)

Texture2D ColorTexture;
SamplerState ColorSampler;

Texture2D BloomTexture;
SamplerState BloomSampler;

// xyz:SceneColorTint.rgb, w:unused
float4 ColorScale0;

// xyz:Bloom1Tint.rgb, w:unused
float4 ColorScale1;

// from the postprocess settings, x:VignetteIntensity, y:SharpenDiv6
float4 TonemapperParams;

// Fine film grain
float3 GrainRandomFull;
float3 GrainScaleBiasJitter;

float EditorNITLevel;

uint bOutputInHDR;

#if EYEADAPTATION_EXPOSURE_FIX != 1
// Default value used when eye adaptation is disabled (e.g fixed exposure) or not available.
float DefaultEyeExposure;
#endif

float4 BloomDirtMaskTint;
Texture2D BloomDirtMaskTexture;
SamplerState BloomDirtMaskSampler;

float4 LensPrincipalPointOffsetScale;
float4 LensPrincipalPointOffsetScaleInverse;

half GrainFromUV(float2 GrainUV) 
{
	half Grain = frac(sin(GrainUV.x + GrainUV.y * 543.31) *  493013.0);
	return Grain;
}

// converts from screen [-1,1] space to the lens [-1,1] viewport space
float2 ConvertScreenViewportSpaceToLensViewportSpace(float2 UV)
{
	return LensPrincipalPointOffsetScale.xy + UV * LensPrincipalPointOffsetScale.zw;
}

float2 ConvertLensViewportSpaceToScreenViewportSpace(float2 UV)
{
	// reference version
	//return (UV - LensPrincipalPointOffsetScale.xy)/LensPrincipalPointOffsetScale.zw;

	// optimized version
	return LensPrincipalPointOffsetScaleInverse.xy + UV * LensPrincipalPointOffsetScaleInverse.zw;
}

half3 LinearToPostTonemapSpace(half3 lin) 
{
#if IOS
	// Note, iOS native output is raw gamma 2.2 not sRGB!
	return pow(lin, 1.0 / 2.2);
#else
	return LinearToSrgbBranchless(lin);
#endif
}

// LUT for color grading
#if USE_VOLUME_LUT == 1
	Texture3D		ColorGradingLUT;
#else
	Texture2D       ColorGradingLUT;
#endif 
SamplerState        ColorGradingLUTSampler;

static const float LUTSize = 32;

half3 ColorLookupTable( half3 LinearColor )
{
	float3 LUTEncodedColor;
	// Encode as ST-2084 (Dolby PQ) values
	#if (DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_ACES1000nitST2084 || DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_ACES2000nitST2084 || DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_ACES1000nitScRGB || DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_ACES2000nitScRGB || DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_LinearEXR || DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_NoToneCurve || DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_WithToneCurve)
		// ST2084 expects to receive linear values 0-10000 in nits.
		// So the linear value must be multiplied by a scale factor to convert to nits.
		LUTEncodedColor = LinearToST2084(LinearColor * LinearToNitsScale);
	#else
		LUTEncodedColor = LinToLog( LinearColor + LogToLin( 0 ) );

	#endif

	float3 UVW = LUTEncodedColor * ((LUTSize - 1) / LUTSize) + (0.5f / LUTSize);

#if USE_VOLUME_LUT == 1
	half3 OutDeviceColor = Texture3DSample( ColorGradingLUT, ColorGradingLUTSampler, UVW ).rgb;
#else
	half3 OutDeviceColor = UnwrappedTexture3DSample( ColorGradingLUT, ColorGradingLUTSampler, UVW, LUTSize ).rgb;
#endif
	
	return OutDeviceColor * 1.05;
}

float SwitchVerticalAxis;

#ifndef NEEDTOSWITCHVERTICLEAXIS
#define NEEDTOSWITCHVERTICLEAXIS 0
#endif

// can be optimized
float2 ScreenPosToUV(float2 ScreenPos, float2 ExtentInverse)
{
	float2 UV = (ScreenPos * Color_ScreenPosToViewportScale + Color_ScreenPosToViewportBias) * ExtentInverse;

#if NEEDTOSWITCHVERTICLEAXIS
	UV.y = 1.0 - UV.y;
#endif

	return UV;
}

float2 UVToScreenPos(float2 UV, float2 Extent)
{
#if NEEDTOSWITCHVERTICLEAXIS
	UV.y = 1.0 - UV.y;
#endif

	return (UV * Extent - Color_ScreenPosToViewportBias) / Color_ScreenPosToViewportScale;
}

float4 ChromaticAberrationParams;

void TonemapCommonVS(
	in	float4 Position,
	in	float2 TexCoord,
	out	float3 OutExposureScaleVignette,
	out	float4 OutGrainUV,
	out	float2 OutScreenPos,
	out	float2 OutFullViewUV
	)
{
	// Forward renderer uses view size texture
	// TODO: Looks to be Ronin specific.. check this:
	OutFullViewUV.xy = Position.xy * float2(0.5,-0.5) + 0.5;

#if NEEDTOSWITCHVERTICLEAXIS
	OutFullViewUV.y = 1.0 - OutFullViewUV.y;
#endif

#if EYEADAPTATION_EXPOSURE_FIX == 1
	#if FEATURE_LEVEL >= FEATURE_LEVEL_SM5
		// texture can be GWhiteTexture which is 1x1. It's important we don't read outside bounds.
		OutExposureScaleVignette.x = EyeAdaptationTexture.Load(int3(0, 0, 0)).x;
	#else
		OutExposureScaleVignette.x = EyeAdaptationBuffer[0].x;
	#endif
#else
	// If eye adaptation is disabled (e.g. fixed exposure level ) or  not available.  
	OutExposureScaleVignette.x = DefaultEyeExposure;
#endif

	const float AspectRatio = Output_ViewportSize.y * Output_ViewportSizeInverse.x;

	float2 ColorViewportPos = UVToScreenPos(TexCoord, Color_Extent);

	// Scale vignette to always be a circle with consistent corner intensity.
	float2 LensViewportPos = ConvertScreenViewportSpaceToLensViewportSpace(ColorViewportPos);
	OutExposureScaleVignette.yz = VignetteSpace(LensViewportPos, AspectRatio);

	// Grain
	OutGrainUV.xy = TexCoord + Color_ExtentInverse * float2(-0.5,0.5);
	OutGrainUV.zw = TexCoord + GrainRandomFull.xy;

	// Fringe
	OutScreenPos = UVToScreenPos(TexCoord, Color_Extent);
}

// vertex shader entry point
void MainVS(
	in 					float4 InPosition 				: ATTRIBUTE0,
	in 					float2 InTexCoord 				: ATTRIBUTE1,
	out noperspective 	float2 OutTexCoord 				: TEXCOORD0,
	out noperspective 	float3 OutExposureScaleVignette : TEXCOORD1,
	out noperspective 	float4 OutGrainUV 				: TEXCOORD2,
	out noperspective 	float2 OutScreenPos 			: TEXCOORD3,
	out noperspective 	float2 OutFullViewUV 			: TEXCOORD4,
	out 				float4 OutPosition 				: SV_POSITION
	)
{
#if NEEDTOSWITCHVERTICLEAXIS
	// This is currently the last pass, so flip the texture on V to match D3D
	InTexCoord.y = 1.0 - InTexCoord.y;
#endif

	DrawRectangle(InPosition, InTexCoord, OutPosition, OutTexCoord);
    TonemapCommonVS(OutPosition, OutTexCoord, OutExposureScaleVignette, OutGrainUV, OutScreenPos, OutFullViewUV);
}

// Function graphing
float F0( float x )
{
	return x*saturate( (x - 0.5)/2 );
}

float F1( float x )
{
	return x;
}

float F2( float x )
{
	return x;
}

float F3( float x )
{
	return x;
}

float LineShade( float fx, float y, float dydx, float LineWidth )
{
	return 1 - smoothstep( 0.5 * LineWidth, LineWidth, abs( fx - y ) / sqrt( 1 + Square( dydx ) ) );
}

float3 Graph( float2 ScreenSpacePos )
{
	float2 WindowMin = float2( 0, 0 );
	float2 WindowMax = float2( 1, 1 );
	
	float2 p = ( (ScreenSpacePos + 1) * 0.5 - WindowMin ) * ( WindowMax - WindowMin );
	float LineWidth = dot( WindowMax - WindowMin, 0.0005 );
	
	float3 Color;
	Color  = float3( 1, 0, 0 ) * LineShade( F0(p.x), p.y, ( F0(p.x + LineWidth) - F0(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 0, 1, 0 ) * LineShade( F1(p.x), p.y, ( F1(p.x + LineWidth) - F1(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 0, 0, 1 ) * LineShade( F2(p.x), p.y, ( F2(p.x + LineWidth) - F2(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 1, 1, 0 ) * LineShade( F3(p.x), p.y, ( F3(p.x + LineWidth) - F3(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	//Color += float3( 0, 1, 1 ) * LineShade( F4(p.x), p.y, ( F4(p.x + LineWidth) - F4(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	//Color += float3( 1, 1, 1 ) * LineShade( F5(p.x), p.y, ( F5(p.x + LineWidth) - F5(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	return Color;
}

// @return color in SRGB
float3 SimpleToneMap(float3 HDRColor)
{
	// from http://filmicgames.com/archives/75
//	float3 x = max(0, HDRColor - 0.004f);	return (x * (6.2f * x + 0.5f)) / (x * (6.2f * x + 1.7f) + 0.06f);
	
	// linear/no tonemapper 
	return HDRColor;
}

float max3(float3 In)
{
	return max(In.x, max(In.y, In.z));
}

// @return 0 at low, 1 at high and linear interpolated inbetween
float RemapScalar(float Low, float High, float x)
{
	return (x - Low) / (High - Low);
}

float max4(float4 x)
{
	return max(max(x.r, x.g), max(x.b, x.a));
}

// useful debug helper (not optimized), could be moved into a more common place
// @param DebugTile 0,0 is center, -1,0 is left, 1,0 is right, ...
float2 ComputeCounterStepForTileDebugging(float4 SvPosition, int2 TileSize, out int2 DebugTile, out int2 LocalDebugTilePosition)
{
	// ViewportRect is defined for postprocessing passes
	float2 CenterPos = (Output_ViewportMin + Output_ViewportMax) / 2.0f;
	float2 LeftTopPos = CenterPos - TileSize / 2;

	float2 LocalPos = SvPosition.xy - LeftTopPos;

	DebugTile = floor(LocalPos / TileSize);

	LocalDebugTilePosition = LocalPos - DebugTile * TileSize;

	float2 CounterStep = -DebugTile * TileSize;

	return CounterStep;
}
// useful debug helper (works with ComputeCounterStepForTileDebugging()), could be moved into a more common place
#define OffsetInterpolator(CounterStep, InterpolatorName) \
		InterpolatorName += ddx(InterpolatorName) * CounterStep.x + ddy(InterpolatorName) * CounterStep.y;

half3 LookupSceneColor(float2 SceneUV, int2 PixelOffset)
{
#if (ES3_1_PROFILE && COMPILER_GLSL_ES3_1)
	// slower but always works
	// to prevent "error: Texture offset not supported on GLSL ES"
	return Texture2DSample(ColorTexture, ColorSampler, SceneUV + PixelOffset * Color_ExtentInverse).rgb;
#else
	// faster
	return ColorTexture.SampleLevel(ColorSampler, SceneUV, 0, PixelOffset).rgb;
#endif
}

float4 SampleSceneColor(float2 SceneUV)
{
	#if USE_GRAIN_JITTER
		SceneUV = clamp(SceneUV, Color_UVViewportBilinearMin, Color_UVViewportBilinearMax);
	#endif

	return Texture2DSample(ColorTexture, ColorSampler, SceneUV);
}

float4 TonemapCommonPS(
	float2 UV,
	float3 ExposureScaleVignette,
	float4 GrainUV,
	float2 ScreenPos, // [-1, 1]x[-1, 1]
	float2 FullViewUV,
	float4 SvPosition
	)
{
	float4 OutColor = 0;

#if USE_PREEXPOSURE
	const float OneOverPreExposure = View.OneOverPreExposure;
#else
	const float OneOverPreExposure = 1.f;
#endif

#if DEBUG_TONEMAPPER
	// @param DebugTile 0,0 is center, -1,0 is left, 1,0 is right, ...
	int2 DebugTile;
	int2 LocalDebugTilePosition;
	bool bOutputDebugTile = false;
	{
		// split the screen in a 3x3 layout and add some border (0.3)
		int2 TileSize = floor(Output_ViewportSize / float2(3.3f, 3.3f));
		bool bBorder;

		float2 CounterStep = ComputeCounterStepForTileDebugging(SvPosition, TileSize, DebugTile, LocalDebugTilePosition);

		OffsetInterpolator(CounterStep, UV);
		OffsetInterpolator(CounterStep, GrainUV);
		OffsetInterpolator(CounterStep, ScreenPos);
		OffsetInterpolator(CounterStep, FullViewUV);
	}
	if (all(DebugTile == int2(0, 0)))
	{
		// center is unaltered tonemapper output
		bOutputDebugTile = true;
	}
#endif

	#if USE_GRAIN_JITTER || USE_GRAIN_INTENSITY || USE_GRAIN_QUANTIZATION
		half Grain = GrainFromUV(GrainUV.zw);
	#endif
	float2 SceneUV = UV.xy;
	#if USE_GRAIN_JITTER
		SceneUV = lerp(UV.xy, GrainUV.xy, (1.0 - Grain*Grain) * GrainScaleBiasJitter.z);
	#endif

	#if USE_COLOR_FRINGE
		float2 SceneUVJitter = float2(0.0, 0.0);
		#if USE_GRAIN_JITTER
			SceneUVJitter = SceneUV.xy - UV.xy;
		#endif
		
	        float2 CAScale = ChromaticAberrationParams.rg;
	        float StartOffset = ChromaticAberrationParams.z;

			float2 LensUV = ConvertScreenViewportSpaceToLensViewportSpace(ScreenPos);

	        float4 CAUV;
	        CAUV = LensUV.xyxy - sign(LensUV).xyxy * saturate(abs(LensUV) - StartOffset).xyxy * CAScale.rrgg;

	        CAUV.xy = ConvertLensViewportSpaceToScreenViewportSpace(CAUV.xy);
	        CAUV.zw = ConvertLensViewportSpaceToScreenViewportSpace(CAUV.zw);

			CAUV.xy = ScreenPosToUV(CAUV.xy, Color_ExtentInverse);
	        CAUV.zw = ScreenPosToUV(CAUV.zw, Color_ExtentInverse);

		half4 SceneColor = SampleSceneColor(CAUV.xy + SceneUVJitter.xy);
		half SceneColorG = SampleSceneColor(CAUV.zw + SceneUVJitter.xy).g;
		half SceneColorB = SampleSceneColor(SceneUV).b;
		SceneColor.g = SceneColorG;
		SceneColor.b = SceneColorB;
	#else
		half4 SceneColor = SampleSceneColor(SceneUV);
	#endif

	SceneColor.rgb *= OneOverPreExposure;

	float ExposureScale = ExposureScaleVignette.x;

#if DEBUG_TONEMAPPER
	if (all(DebugTile == int2(-1, 1)))
	{
		// left below to the center is: no ExposureScale
		ExposureScale = 1.0f;
		bOutputDebugTile = true;
	}
#endif

	// 0..x, 0:no effect .. 1:strong, from r.Tonemapper.Sharpen
	// Div6 is to save one instruction
	float SharpenMultiplierDiv6 = TonemapperParams.y;

#if DEBUG_TONEMAPPER
	if (all(DebugTile == int2(0, -1)) || all(DebugTile == int2(-1, -1)))
	{
		// top row: no sharpen
		SharpenMultiplierDiv6 = 0;
		bOutputDebugTile = true;
	}
#endif //DEBUG_TONEMAPPER

#if USE_SHARPEN
	{

		half A0 = Luminance(SceneColor.rgb);

	#if HAS_PIXEL_QUAD_MESSAGE_PASSING_SUPPORT 
		// Use Wave Intrinsics to reduce texture taps
		FPQMPContext PQMP = PQMPInit(floor(SceneUV* Color_Extent));
				
		half4 LuminanceNeighbors;

		half3 C1 = Texture2DSample(ColorTexture, ColorSampler, SceneUV + float2(PQMP.QuadVector.x, 0) * Color_ExtentInverse).rgb * OneOverPreExposure;
		half3 C3 = Texture2DSample(ColorTexture, ColorSampler, SceneUV + float2(0, PQMP.QuadVector.y) * Color_ExtentInverse).rgb * OneOverPreExposure;
		LuminanceNeighbors.x = Luminance(C1);
		LuminanceNeighbors.y = Luminance(C3);
		
		half3 C2 = PQMPReadX(PQMP, SceneColor.rgb);
		half3 C4 = PQMPReadY(PQMP, SceneColor.rgb);
		LuminanceNeighbors.z =  PQMPReadX(PQMP,A0);
		LuminanceNeighbors.w =  PQMPReadY(PQMP,A0);
	#else
		half3 C1 = LookupSceneColor(SceneUV, int2(-1,  0)) * OneOverPreExposure;
		half3 C2 = LookupSceneColor(SceneUV, int2( 1,  0)) * OneOverPreExposure;
		half3 C3 = LookupSceneColor(SceneUV, int2( 0, -1)) * OneOverPreExposure;
		half3 C4 = LookupSceneColor(SceneUV, int2( 0,  1)) * OneOverPreExposure;
		half4 LuminanceNeighbors = half4(Luminance(C1), Luminance(C2), Luminance(C3), Luminance(C4));
	#endif

		// compute mask to not sharpen near very bright HDR content
		// Note: using max instead of summming up saves 1 instruction
		// Note: We could multiply this to tweak the edge weight but it might instroduce a cost
		half HDREdge = ExposureScale * max4(abs(A0 - LuminanceNeighbors));
	
		// 0..1
		half EdgeMask = saturate(1.0f - HDREdge);

#if DEBUG_TONEMAPPER
		if (all(DebugTile == int2(1, 0)))
		{
			// right to the center is: Sharpen EdgeMask
			OutColor = EdgeMask; 
			return OutColor;
		}
#endif //DEBUG_TONEMAPPER

		// -1:sharpen, 0:no effect, 1:blur
		float LerpFactor = -EdgeMask * SharpenMultiplierDiv6;

		// optimized, Div6 went into the C++ code
		half3 DeltaColor = (C1 + C2 + C3 + C4) - SceneColor.rgb * 4;
		SceneColor.rgb += DeltaColor * LerpFactor;
	}
#endif

	#if USE_GAMMA_ONLY

		SceneColor.rgb *= ExposureScale;

		OutColor.rgb = pow(SceneColor.rgb, InverseGamma.x);

	#else 

		#if METAL_MSAA_HDR_DECODE
			// look for PreTonemapMSAA 
			SceneColor.rgb *= rcp(SceneColor.r*(-0.299) + SceneColor.g*(-0.587) + SceneColor.b*(-0.114) + 1.0);
			// Try to kill negatives and NaNs here
			SceneColor.rgb = max(SceneColor.rgb, 0); 
		#endif
	
		half3 LinearColor = SceneColor.rgb * ColorScale0.rgb;

		#if USE_BLOOM
			float2 BloomUV = ColorToBloom_Scale * UV + ColorToBloom_Bias;
			BloomUV = clamp(BloomUV, Bloom_UVViewportBilinearMin, Bloom_UVViewportBilinearMax);
			#if ES3_1_PROFILE
				BloomUV = FullViewUV.xy;
			#endif
			float4 CombinedBloom = Texture2DSample(BloomTexture, BloomSampler, BloomUV);
			CombinedBloom.rgb *= OneOverPreExposure; // Standard bloom path, convolution path has bloom already in scene color.

			//float2 DirtViewportUV = (SvPosition.xy - float2(Output_ViewportMin)) * Output_ViewportSizeInverse; 

#if DEBUG_TONEMAPPER
			if (all(DebugTile == int2(-1, -1)))
			{
				// left to the center is: no bloom
				CombinedBloom = 0;
				bOutputDebugTile = true;
			}
			if (all(DebugTile == int2(1, -1)))
			{
				// right to the center is: bloom only
				LinearColor = 0;
				bOutputDebugTile = true;
			}
#endif //DEBUG_TONEMAPPER

			#if FEATURE_LEVEL == FEATURE_LEVEL_ES3_1
				// Support sunshaft and vignette for mobile, and we have applied the BloomIntensity and the BloomDirtMask at the sun merge pass.
				LinearColor = LinearColor.rgb * CombinedBloom.a + CombinedBloom.rgb;
			#else
			
				float2 DirtLensUV = ConvertScreenViewportSpaceToLensViewportSpace(ScreenPos) * float2(1.0f, -1.0f);

				float3 BloomDirtMaskColor = Texture2DSample(BloomDirtMaskTexture, BloomDirtMaskSampler, DirtLensUV * .5f + .5f).rgb * BloomDirtMaskTint.rgb;

				LinearColor += CombinedBloom.rgb * (ColorScale1.rgb + BloomDirtMaskColor); 
			#endif
		#endif

		#if NO_EYEADAPTATION_EXPOSURE_FIX == 1
			ExposureScale = BloomDirtMaskTint.w;
		#endif
		
		LinearColor *= ExposureScale;

		#if USE_VIGNETTE
			LinearColor.rgb *= ComputeVignetteMask( ExposureScaleVignette.yz, TonemapperParams.x );
		#endif

		#if USE_GRAIN_INTENSITY
			// Needs to go before tonemapping.
			half GrainMul = Grain * GrainScaleBiasJitter.x + GrainScaleBiasJitter.y;
			LinearColor.rgb *= GrainMul;
		#endif

			half3 OutDeviceColor = ColorLookupTable(LinearColor);

		half LuminanceForPostProcessAA  = dot(OutDeviceColor, half3(0.299f, 0.587f, 0.114f));

		#if USE_GRAIN_QUANTIZATION
			#if DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_NoToneCurve
				#error LinearNoToneCurve device requires no Grain Quantization
			#endif
			#if DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_WithToneCurve
				#error LinearWithToneCurve device requires no Grain Quantization
			#endif
		// Needs to go after tonemapping. 
			#if USE_LINEAR_FLOAT_RT
				half GrainQuantization = 1.0/1024.0;
			#else
				half GrainQuantization = 1.0/256.0;
			#endif

			half GrainAdd = (Grain * GrainQuantization) + (-0.5 * GrainQuantization);
			OutDeviceColor.rgb += GrainAdd;
		#endif

		// RETURN_COLOR not needed unless writing to SceneColor
		OutColor = float4(OutDeviceColor, saturate(LuminanceForPostProcessAA));

		#if USE_LINEAR_FLOAT_RT
			OutColor.rgb = sRGBToLinear( OutColor.rgb );
		#endif

		#if DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_ACES1000nitScRGB || DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_ACES2000nitScRGB
			OutColor.xyz = ST2084ToScRGB(OutColor.xyz, DIM_OUTPUT_DEVICE);

		#elif DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_LinearEXR
			OutColor.xyz = ST2084ToLinear(OutColor.xyz);
		#elif DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_NoToneCurve
			OutColor.xyz = OutDeviceColor;
		#elif DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_WithToneCurve
			OutColor.xyz = OutDeviceColor;
		#endif

	#endif
	
	#if FEATURE_LEVEL <= FEATURE_LEVEL_ES3_1 || POST_PROCESS_ALPHA == 2 || (POST_PROCESS_ALPHA == 1 && DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_NoToneCurve)  || (POST_PROCESS_ALPHA == 1 && DIM_OUTPUT_DEVICE == TONEMAPPER_OUTPUT_WithToneCurve)
		OutColor.a = SceneColor.a;
	#endif

#if DEBUG_TONEMAPPER
	if (!bOutputDebugTile)
	{
		// the original tonemapped color is only in the center
		// other tiles can output like this:
		//  if(all(DebugTile == int2(1, 0)))
		//    { OutColor = ..; return; }
		// or
		//  if(all(DebugTile == int2(1, 0)))
		//    { ..; bOutputDebugTile = true; }
		OutColor = 0;
	}
	if (any(LocalDebugTilePosition == int2(0, 0)))
	{
		// border grid
		OutColor = 1;
	}
#endif //DEBUG_TONEMAPPER

#if SM5_PROFILE && !USE_GAMMA_ONLY
	// If HDR in the editor need to convert from PQ space to linear sRGB
	BRANCH
	if(bOutputInHDR)
	{
		OutColor.rgb = ST2084ToLinear(OutColor.rgb);
		OutColor.rgb = OutColor.rgb / EditorNITLevel;
        OutColor.rgb = LinearToPostTonemapSpace(OutColor.rgb);
	}
#endif
	return OutColor;
}

// pixel shader entry point
void MainPS(
	in noperspective float2 UV : TEXCOORD0,
	in noperspective float3 InExposureScaleVignette : TEXCOORD1,
	in noperspective float4 GrainUV : TEXCOORD2,
	in noperspective float2 ScreenPos : TEXCOORD3,
	in noperspective float2 FullViewUV : TEXCOORD4,
	float4 SvPosition : SV_POSITION,		// after all interpolators
	out float4 OutColor : SV_Target0
	)
{
    OutColor = TonemapCommonPS(UV, InExposureScaleVignette, GrainUV, ScreenPos, FullViewUV, SvPosition);
}

#if COMPUTESHADER
RWTexture2D<float4> RWOutputTexture;

[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void MainCS(uint2 DispatchThreadId : SV_DispatchThreadID)
{
	float4 SvPosition = float4((float2)DispatchThreadId + Output_ViewportMin + 0.5f, 0.0f, 1.0f);
	float2 UV = SvPosition.xy * Output_ExtentInverse;
	float4 InScreenPos = float4(UV*2-1,0,1);

	if (IsComputeUVOutOfBounds(UV))
	{
		return;
	}

	float3 ExposureScaleVignette;
	float4 GrainUV;
	float2 FullViewUV, ScreenPos;	
	TonemapCommonVS(InScreenPos, UV, ExposureScaleVignette, GrainUV, ScreenPos, FullViewUV);

	float4 OutColor = TonemapCommonPS(UV, ExposureScaleVignette, GrainUV, ScreenPos, FullViewUV, SvPosition);

	uint2 PixelPos = DispatchThreadId + Output_ViewportMin;
#if NEEDTOSWITCHVERTICLEAXIS
	PixelPos.y = (uint)(Output_Extent.y) - PixelPos.y;
#endif
	RWOutputTexture[PixelPos] = OutColor;
}
#endif


// Mobile version
// TODO: Convert float to half.

float FringeIntensity;

float4 BufferSizeAndInvSize;
float4 DofBlurSizeAndInvSize;

// vertex shader entry point
void MainVS_Mobile(
	in float4 InPosition : ATTRIBUTE0,
	in float2 InTexCoord : ATTRIBUTE1,
	out float4 OutTexCoord : TEXCOORD0,
	out float4 OutFineDofGrain : TEXCOORD1,
	out float4 OutFullViewUV : TEXCOORD2,
	out float3 OutVignetteExposureScale : TEXCOORD3,
	out float2 OutTexCoords[4] : TEXCOORD4,
	out float4 OutFringeTexCoords : FRINGE_COORDS,
	out float4 OutPosition : SV_POSITION
	)
{
#if NEEDTOSWITCHVERTICLEAXIS
	// This is currently the last pass, so flip the texture on V to match D3D
	InTexCoord.y = 1.0-InTexCoord.y;
#endif

#if EYEADAPTATION_EXPOSURE_FIX == 1
	// texture can be GWhiteTexture which is 1x1. It's important we don't read outside bounds.
	OutVignetteExposureScale.z = EyeAdaptationBuffer[0].x;
#else
	// If eye adaptation is disabled (e.g. fixed exposure level ) or  not available.  
	OutVignetteExposureScale.z = DefaultEyeExposure;
#endif

	DrawRectangle(InPosition, InTexCoord, OutPosition, OutTexCoord.xy);
	OutTexCoord = float4(OutTexCoord.xy, OutPosition.xy);

	// Fine adjustment is inside the possible non-full viewport in the full resolution texture.
	OutFineDofGrain.xy = OutTexCoord.xy + BufferSizeAndInvSize.zw * float2(-0.5,0.5);
	// Want grain and a second UV based on the knowledge that the source texture has a full viewport.
	OutFullViewUV.xy = OutPosition.xy * float2(0.5,-0.5) + 0.5;
	#if NEEDTOSWITCHVERTICLEAXIS
		// This is currently the last pass, so flip the texture on V to match D3D
		OutFullViewUV.y = 1.0 - OutFullViewUV.y;
	#endif
	// For DOF attempt to undo sampling bias for the first transition region.
	// This is better for the fine transition, breaks down for the larger bokeh.
	// This is the best compromise for mobile using 4 bilinear taps only.
	OutFullViewUV.zw = OutFullViewUV.xy + DofBlurSizeAndInvSize.zw * float2(0.25,-0.5);
	OutFineDofGrain.zw = OutFullViewUV.xy + GrainRandomFull.xy;
	// NEWS
	OutTexCoords[0] = OutTexCoord.xy + BufferSizeAndInvSize.zw * float2( 0,-1);
	OutTexCoords[1] = OutTexCoord.xy + BufferSizeAndInvSize.zw * float2( 1, 0);
	OutTexCoords[2] = OutTexCoord.xy + BufferSizeAndInvSize.zw * float2(-1, 0);
	OutTexCoords[3] = OutTexCoord.xy + BufferSizeAndInvSize.zw * float2( 0, 1);

	float2 ColorViewportPos = UVToScreenPos(OutTexCoord.xy, BufferSizeAndInvSize.xy);

	// Scale vignette to always be a circle with consistent corner intensity.
	float2 LensViewportPos = ConvertScreenViewportSpaceToLensViewportSpace(ColorViewportPos);
	OutVignetteExposureScale.xy = VignetteSpace(LensViewportPos);

	// Compute fringe tex coord offsets
	BRANCH
	if (FringeIntensity > 0.0)
	{
		// Wavelength of primaries in nm
		half PrimaryR = 611.3f;
		half PrimaryG = 549.1f;
		half PrimaryB = 464.3f;

		// Simple lens chromatic aberration is roughly linear in wavelength
		float ScaleR = 0.007f * (PrimaryR - PrimaryB);
		float ScaleG = 0.007f * (PrimaryG - PrimaryB);

		// Fringe
		float2 ScreenPos = UVToScreenPos(OutTexCoord.xy, BufferSizeAndInvSize.xy);
		OutFringeTexCoords.xy = ScreenPosToUV(ScreenPos * (1.0/(1.0 + (FringeIntensity * ScaleG))), BufferSizeAndInvSize.zw);
		OutFringeTexCoords.zw = ScreenPosToUV(ScreenPos * (1.0/(1.0 + (FringeIntensity * ScaleR))), BufferSizeAndInvSize.zw);
	}
	else
	{
		OutFringeTexCoords = 0.0;
	}
}

float4 OverlayColor;
float SRGBAwareTarget;

Texture2D SceneColorTexture;
SamplerState SceneColorSampler;

Texture2D DofBlurTexture;
SamplerState DofBlurSampler;

Texture2D SunShaftAndDofTexture;
SamplerState SunShaftAndDofSampler;

void MainPS_Mobile(
	in float4 UVAndScreenPos : TEXCOORD0,
	in float4 FineDofGrain : TEXCOORD1,
	in float4 FullViewUV : TEXCOORD2,
	in float3 InVignetteExposureScale : TEXCOORD3,
	in float2 InTexCoords[4] : TEXCOORD4,
	in float4 InFringeTexCoords : FRINGE_COORDS,
	out half4 OutColor : SV_Target0
	)
{
	float2 UV = UVAndScreenPos.xy;
	float2 ScreenSpacePos = UVAndScreenPos.zw;

	half4 SceneColor;

#if USE_PREEXPOSURE
	const float OneOverPreExposure = View.OneOverPreExposure;
#else
	const float OneOverPreExposure = 1.f;
#endif
	
	BRANCH
	if (FringeIntensity > 0.0)
	{
		SceneColor.r = Texture2DSample(SceneColorTexture, SceneColorSampler, InFringeTexCoords.zw).r;
		SceneColor.g = Texture2DSample(SceneColorTexture, SceneColorSampler, InFringeTexCoords.xy).g;
		SceneColor.b = Texture2DSample(SceneColorTexture, SceneColorSampler, UV).b;
		SceneColor.a = 1.0;
	}
	else
	{
		SceneColor = Texture2DSample(SceneColorTexture, SceneColorSampler, UV);
	}

	#if USE_GAMMA_ONLY
		
		#if FEATURE_LEVEL == FEATURE_LEVEL_ES3_1
			OutColor.rgb = pow(SceneColor.rgb, InverseGamma.x);
		#else
			OutColor.rgb = sqrt(SceneColor.rgb);
		#endif

	#else

		#if USE_GRAIN_JITTER || USE_GRAIN_INTENSITY || USE_GRAIN_QUANTIZATION
			half Grain = GrainFromUV(FineDofGrain.zw);
		#endif

		#if USE_DOF
			half4 DofFine = Texture2DSample(SceneColorTexture, SceneColorSampler, FineDofGrain.xy);
			half4 Dof = Texture2DSample(DofBlurTexture, DofBlurSampler, FullViewUV.zw);
			half DofCoc = Texture2DSample(SunShaftAndDofTexture, SunShaftAndDofSampler, UV).r;
			// Convert alpha back into circle of confusion.
			SceneColor.a = max(Dof.a, abs(DofCoc * 2.0 - 1.0));
			// Convert circle of confusion into blend factors.		
			half2 ScaleBias = CocBlendScaleBias(); // Constant.
			half DofAmount = saturate(SceneColor.a * ScaleBias.x + ScaleBias.y);
			half2 ScaleBias2 = CocBlendScaleBiasFine(); // Constant.
			half DofAmountFine = saturate(SceneColor.a * ScaleBias2.x + ScaleBias2.y);
			#if USE_GRAIN_JITTER
				// Grain can increase fine DOF.
				DofAmountFine = max((1.0-Grain*Grain) * GrainScaleBiasJitter.z, DofAmountFine);
			#endif
			// Blend in fine DOF.
			SceneColor.rgb = lerp(SceneColor.rgb, DofFine.rgb, DofAmountFine);
			// Blend in coarse DOF.
			SceneColor.rgb = lerp(SceneColor.rgb, Dof.rgb, DofAmount);
		#else
			#if USE_GRAIN_JITTER
				// Do jitter for grain.
				half4 DofFine = Texture2DSample(SceneColorTexture, SceneColorSampler, FineDofGrain.xy);
				// Grain jitter.
				SceneColor.rgb = lerp(SceneColor.rgb, DofFine.rgb, (1.0-Grain*Grain) * GrainScaleBiasJitter.z);
			#endif
		#endif

		#if METAL_MSAA_HDR_DECODE
			// Do after jitter for grain as an optimization.
			SceneColor.rgb *= rcp(SceneColor.r*(-0.299) + SceneColor.g*(-0.587) + SceneColor.b*(-0.114) + 1.0);
			// Try to kill negatives and NaNs here
			SceneColor.rgb = max(SceneColor.rgb, 0);
		#endif

		#if !USE_DOF
			// Set so temporal AA shader knows everything is in focus.
			SceneColor.a = 0.0;
		#endif

		// Match PC naming.
		half3 LinearColor = SceneColor.rgb * OneOverPreExposure;

		float ExposureScale = InVignetteExposureScale.z;
		
		#if USE_VIGNETTE
			LinearColor.rgb *= ComputeVignetteMask(InVignetteExposureScale.xy, TonemapperParams.x );
		#endif

		// It is faster to do vignette as a texture lookup + mad because this is an ALU bound shader.
		#if (USE_BLOOM || USE_LIGHT_SHAFTS || USE_VIGNETTE)
		{
			half4 CombinedBloomSunVignette = Texture2DSample(BloomTexture, BloomSampler, FullViewUV.xy);
			LinearColor.rgb = LinearColor.rgb * CombinedBloomSunVignette.a + CombinedBloomSunVignette.rgb * OneOverPreExposure;
		}
		#endif

		LinearColor *= ExposureScale;

		#if USE_GRAIN_INTENSITY
			// Needs to go before tonemapping.
			half GrainMul = Grain * GrainScaleBiasJitter.x + GrainScaleBiasJitter.y;
			LinearColor.rgb *= GrainMul;
		#endif

		half3 FilmColor = FilmPostProcess(LinearColor.rgb);
		half3 TonemappedColor;
		if (SRGBAwareTarget > 0.5)
		{
			// skip sRGB conversion if HW conversion will take place.
			TonemappedColor = FilmColor;
		}
		else
		{
			// Apply conversion to sRGB (this must be an exact sRGB conversion else darks are bad).
			TonemappedColor = LinearToPostTonemapSpace(FilmColor);
		}


		// Blend with custom LDR color, used for Fade track in Matinee.
		// This is the 101% wrong way to do this,
		//  - It adds an extra redundant lerp.
		//  - It is not going to work with the future-forward ES3 fast path of sRGB output.
		//  - And it does super ugly non-linear blending.
		// The right way is to adjust exposure instead.
		TonemappedColor = lerp(TonemappedColor.rgb, OverlayColor.rgb, OverlayColor.a);

		#if USE_GRAIN_QUANTIZATION
			// Needs to go after tonemapping.
			half GrainQuantization = 1.0/256.0;
			half GrainAdd = (Grain * GrainQuantization) + (-0.5 * GrainQuantization);
			TonemappedColor.rgb += GrainAdd;
		#endif
			
			OutColor = half4(TonemappedColor, SceneColor.a);

	#endif
}
